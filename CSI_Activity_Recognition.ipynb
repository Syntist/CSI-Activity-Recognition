{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CSI-Activity-Recognition\n",
        "\n",
        "Human Activity Recognition using Channel State Information for Wifi Applications\n",
        "\n",
        "A simple Tensorflow 2.0+ model using Bidirectional LSTM stacked with one Attention Layer.\n",
        "\n",
        "This code extends the previsous work of paper [A Survey on Behaviour Recognition Using WiFi Channel State Information](http://ieeexplore.ieee.org/document/8067693/) ([corresponding code](https://github.com/ermongroup/Wifi_Activity_Recognition)).\n",
        "\n",
        "## Dataset Preparation\n",
        "\n",
        "Download the public dataset from [here](https://drive.google.com/file/d/19uH0_z1MBLtmMLh8L4BlNA0w-XAFKipM/view?usp=sharing)."
      ],
      "metadata": {
        "id": "0RnpSPTSGdyi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WM9gjMxJB5ME"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "The Codes in this file are used to classify Human Activity using Channel State Information. \n",
        "The deep learning architecture used here is Bidirectional LSTM stacked with One Attention Layer.\n",
        "Author: https://github.com/ludlows\n",
        "2019-12\n",
        "\"\"\"\n",
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import os\n",
        "import csv\n",
        "\n",
        "\n",
        "def merge_csi_label(csifile, labelfile, win_len=1000, thrshd=0.6, step=200):\n",
        "    \"\"\"\n",
        "    Merge CSV files into a Numpy Array  X,  csi amplitude feature\n",
        "    Returns Numpy Array X, Shape(Num, Win_Len, 90)\n",
        "    Args:\n",
        "        csifile  :  str, csv file containing CSI data\n",
        "        labelfile:  str, csv fiel with activity label \n",
        "        win_len  :  integer, window length\n",
        "        thrshd   :  float,  determine if an activity is strong enough inside a window\n",
        "        step     :  integer, sliding window by step\n",
        "    \"\"\"\n",
        "    activity = []\n",
        "    with open(labelfile, 'r') as labelf:\n",
        "        reader = csv.reader(labelf)\n",
        "        for line in reader:\n",
        "            label  = line[0]\n",
        "            if label == 'NoActivity':\n",
        "                activity.append(0)\n",
        "            else:\n",
        "                activity.append(1)\n",
        "    activity = np.array(activity)\n",
        "    csi = []\n",
        "    with open(csifile, 'r') as csif:\n",
        "        reader = csv.reader(csif)\n",
        "        for line in reader:\n",
        "            line_array = np.array([float(v) for v in line])\n",
        "            # extract the amplitude only\n",
        "            line_array = line_array[1:91]\n",
        "            csi.append(line_array[np.newaxis,...])\n",
        "    csi = np.concatenate(csi, axis=0)\n",
        "    assert(csi.shape[0] == activity.shape[0])\n",
        "    # screen the data with a window\n",
        "    index = 0\n",
        "    feature = []\n",
        "    while index + win_len <= csi.shape[0]:\n",
        "        cur_activity = activity[index:index+win_len]\n",
        "        if np.sum(cur_activity)  <  thrshd * win_len:\n",
        "            index += step\n",
        "            continue\n",
        "        cur_feature = np.zeros((1, win_len, 90))\n",
        "        cur_feature[0] = csi[index:index+win_len, :]\n",
        "        feature.append(cur_feature)\n",
        "        index += step\n",
        "    return np.concatenate(feature, axis=0)\n",
        "\n",
        "\n",
        "def extract_csi_by_label(raw_folder, label, labels, save=False, win_len=1000, thrshd=0.6, step=200):\n",
        "    \"\"\"\n",
        "    Returns all the samples (X,y) of \"label\" in the entire dataset\n",
        "    Args:\n",
        "        raw_foler: The path of Dataset folder\n",
        "        label    : str, could be one of labels\n",
        "        labels   : list of str, ['bed', 'fall', 'pickup', 'run', 'sitdown', 'standup', 'walk']\n",
        "        save     : boolean, choose whether save the numpy array \n",
        "        win_len  :  integer, window length\n",
        "        thrshd   :  float,  determine if an activity is strong enough inside a window\n",
        "        step     :  integer, sliding window by step\n",
        "    \"\"\"\n",
        "    print('Starting Extract CSI for Label {}'.format(label))\n",
        "    label = label.lower()\n",
        "    if not label in labels:\n",
        "        raise ValueError(\"The label {} should be among 'bed','fall','pickup','run','sitdown','standup','walk'\".format(labels))\n",
        "    \n",
        "    data_path_pattern = os.path.join(raw_folder, 'input_*' + label + '*.csv')\n",
        "    input_csv_files = sorted(glob.glob(data_path_pattern))\n",
        "    annot_csv_files = [os.path.basename(fname).replace('input_', 'annotation_') for fname in input_csv_files]\n",
        "    annot_csv_files = [os.path.join(raw_folder, fname) for fname in annot_csv_files]\n",
        "    feature = []\n",
        "    index = 0\n",
        "    for csi_file, label_file in zip(input_csv_files, annot_csv_files):\n",
        "        index += 1\n",
        "        if not os.path.exists(label_file):\n",
        "            print('Warning! Label File {} doesn\\'t exist.'.format(label_file))\n",
        "            continue\n",
        "        feature.append(merge_csi_label(csi_file, label_file, win_len=win_len, thrshd=thrshd, step=step))\n",
        "        print('Finished {:.2f}% for Label {}'.format(index / len(input_csv_files) * 100,label))\n",
        "    \n",
        "    feat_arr = np.concatenate(feature, axis=0)\n",
        "    if save:\n",
        "        np.savez_compressed(\"X_{}_win_{}_thrshd_{}percent_step_{}.npz\".format(\n",
        "            label, win_len, int(thrshd*100), step), feat_arr)\n",
        "    # one hot\n",
        "    feat_label = np.zeros((feat_arr.shape[0], len(labels)))\n",
        "    feat_label[:, labels.index(label)] = 1\n",
        "    return feat_arr, feat_label\n",
        "\n",
        "\n",
        "def train_valid_split(numpy_tuple, train_portion=0.9, seed=379):\n",
        "    \"\"\"\n",
        "    Returns Train and Valid Datset with the format of (x_train, y_train, x_valid, y_valid),\n",
        "    where x_train and y_train are shuffled randomly.\n",
        "\n",
        "    Args:\n",
        "        numpy_tuple  : tuple of numpy array: (x_bed, x_fall, x_pickup, x_run, x_sitdown, x_standup, x_walk)\n",
        "        train_portion: float, range (0,1)\n",
        "        seed         : random seed\n",
        "    \"\"\"\n",
        "    np.random.seed(seed=seed)\n",
        "    x_train = []\n",
        "    x_valid = []\n",
        "    y_valid = []\n",
        "    y_train = []\n",
        "\n",
        "    for i, x_arr in enumerate(numpy_tuple):\n",
        "        index = np.random.permutation([i for i in range(x_arr.shape[0])])\n",
        "        split_len = int(train_portion * x_arr.shape[0])\n",
        "        x_train.append(x_arr[index[:split_len], ...])\n",
        "        tmpy = np.zeros((split_len,7))\n",
        "        tmpy[:, i] = 1\n",
        "        y_train.append(tmpy)\n",
        "        x_valid.append(x_arr[index[split_len:],...])\n",
        "        tmpy = np.zeros((x_arr.shape[0]-split_len,7))\n",
        "        tmpy[:, i] = 1\n",
        "        y_valid.append(tmpy)\n",
        "    \n",
        "    x_train = np.concatenate(x_train, axis=0)\n",
        "    y_train = np.concatenate(y_train, axis=0)\n",
        "    x_valid = np.concatenate(x_valid, axis=0)\n",
        "    y_valid = np.concatenate(y_valid, axis=0)\n",
        "\n",
        "    index = np.random.permutation([i for i in range(x_train.shape[0])])\n",
        "    x_train = x_train[index, ...]\n",
        "    y_train = y_train[index, ...]\n",
        "    return x_train, y_train, x_valid, y_valid\n",
        "    \n",
        "    \n",
        "\n",
        "def extract_csi(raw_folder, labels, save=False, win_len=1000, thrshd=0.6, step=200):\n",
        "    \"\"\"\n",
        "    Return List of Array in the format of [X_label1, y_label1, X_label2, y_label2, .... X_Label7, y_label7]\n",
        "    Args:\n",
        "        raw_folder: the folder path of raw CSI csv files, input_* annotation_*\n",
        "        labels    : all the labels existing in the folder\n",
        "        save      : boolean, choose whether save the numpy array \n",
        "        win_len   :  integer, window length\n",
        "        thrshd    :  float,  determine if an activity is strong enough inside a window\n",
        "        step      :  integer, sliding window by step\n",
        "    \"\"\"\n",
        "    ans = []\n",
        "    for label in labels:\n",
        "        feature_arr, label_arr = extract_csi_by_label(raw_folder, label, labels, save, win_len, thrshd, step)\n",
        "        ans.append(feature_arr)\n",
        "        ans.append(label_arr)\n",
        "    return tuple(ans)\n",
        "\n",
        "\n",
        "class AttenLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Attention Layers used to Compute Weighted Features along Time axis\n",
        "    Args:\n",
        "        num_state :  number of hidden Attention state\n",
        "    \n",
        "    2019-12, https://github.com/ludlows\n",
        "    \"\"\"\n",
        "    def __init__(self, num_state, **kw):\n",
        "        super(AttenLayer, self).__init__(**kw)\n",
        "        self.num_state = num_state\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight('kernel', shape=[input_shape[-1], self.num_state])\n",
        "        self.bias = self.add_weight('bias', shape=[self.num_state])\n",
        "        self.prob_kernel = self.add_weight('prob_kernel', shape=[self.num_state])\n",
        "\n",
        "    def call(self, input_tensor):\n",
        "        atten_state = tf.tanh(tf.tensordot(input_tensor, self.kernel, axes=1) + self.bias)\n",
        "        logits = tf.tensordot(atten_state, self.prob_kernel, axes=1)\n",
        "        prob = tf.nn.softmax(logits)\n",
        "        weighted_feature = tf.reduce_sum(tf.multiply(input_tensor, tf.expand_dims(prob, -1)), axis=1)\n",
        "        return weighted_feature\n",
        "    \n",
        "    # for saving the model\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'num_state': self.num_state,})\n",
        "        return config\n",
        "\n",
        "\n",
        "class CSIModelConfig:\n",
        "    \"\"\"\n",
        "    class for Human Activity Recognition (\"bed\", \"fall\", \"pickup\", \"run\", \"sitdown\", \"standup\", \"walk\")\n",
        "    Using CSI (Channel State Information)\n",
        "    Specifically, the author here wants to classify Human Activity using Channel State Information. \n",
        "    The deep learning architecture used here is Bidirectional LSTM stacked with One Attention Layer.\n",
        "       2019-12, https://github.com/ludlows\n",
        "    Args:\n",
        "        win_len   :  integer (1000 default) window length for batching sequence\n",
        "        step      :  integer (200  default) sliding window by this step\n",
        "        thrshd    :  float   (0.6  default) used to check if the activity is intensive inside a window\n",
        "        downsample:  integer >=1 (2 default) downsample along the time axis\n",
        "    \"\"\"\n",
        "    def __init__(self, win_len=1000, step=200, thrshd=0.6, downsample=2):\n",
        "        self._win_len = win_len\n",
        "        self._step = step\n",
        "        self._thrshd = thrshd\n",
        "        self._labels = (\"bed\", \"fall\", \"pickup\", \"run\", \"sitdown\", \"standup\", \"walk\")\n",
        "        self._downsample = downsample\n",
        "\n",
        "    def preprocessing(self, raw_folder, save=False):\n",
        "        \"\"\"\n",
        "        Returns the Numpy Array for training within the format of (X_lable1, y_label1, ...., X_label7, y_label7)\n",
        "        Args:\n",
        "            raw_folder: the folder containing raw CSI \n",
        "            save      : choose if save the numpy array\n",
        "        \"\"\"\n",
        "        numpy_tuple = extract_csi(raw_folder, self._labels, save, self._win_len, self._thrshd, self._step)\n",
        "        if self._downsample > 1:\n",
        "            return tuple([v[:, ::self._downsample,...] if i%2 ==0 else v for i, v in enumerate(numpy_tuple)])\n",
        "        return numpy_tuple\n",
        "    \n",
        "    def load_csi_data_from_files(self, np_files):\n",
        "        \"\"\"\n",
        "        Returns the Numpy Array for training within the format of (X_lable1, y_label1, ...., X_label7, y_label7)\n",
        "        Args:\n",
        "            np_files: ('x_bed.npz', 'x_fall.npz', 'x_pickup.npz', 'x_run.npz', 'x_sitdown.npz', 'x_standup.npz', 'x_walk.npz')\n",
        "        \"\"\"\n",
        "        if len(np_files) != 7:\n",
        "            raise ValueError('There should be 7 numpy files for bed, fall, pickup, run, sitdown, standup, walk.')\n",
        "        x = [np.load(f)['arr_0'] for f in np_files]\n",
        "        if self._downsample > 1:\n",
        "            x = [arr[:,::self._downsample, :] for arr in x]\n",
        "        y = [np.zeros((arr.shape[0], len(self._labels))) for arr in x]\n",
        "        numpy_list = []\n",
        "        for i in range(len(self._labels)):\n",
        "            y[i][:,i] = 1\n",
        "            numpy_list.append(x[i])\n",
        "            numpy_list.append(y[i])\n",
        "        return tuple(numpy_list)\n",
        "\n",
        "\n",
        "    \n",
        "    def build_model(self, n_unit_lstm=200, n_unit_atten=400):\n",
        "        \"\"\"\n",
        "        Returns the Tensorflow Model which uses AttenLayer\n",
        "        \"\"\"\n",
        "        if self._downsample > 1:\n",
        "            length = len(np.ones((self._win_len,))[::self._downsample])\n",
        "            x_in = tf.keras.Input(shape=(length, 90))\n",
        "        else:\n",
        "            x_in = tf.keras.Input(shape=(self._win_len, 90))\n",
        "        x_tensor = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=n_unit_lstm, return_sequences=True))(x_in)\n",
        "        x_tensor = AttenLayer(n_unit_atten)(x_tensor)\n",
        "        pred = tf.keras.layers.Dense(len(self._labels), activation='softmax')(x_tensor)\n",
        "        model = tf.keras.Model(inputs=x_in, outputs=pred)\n",
        "        return model\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def load_model(hdf5path):\n",
        "        \"\"\"\n",
        "        Returns the Tensorflow Model for AttenLayer\n",
        "        Args:\n",
        "            hdf5path: str, the model file path\n",
        "        \"\"\"\n",
        "        model = tf.keras.models.load_model(hdf5path, custom_objects={'AttenLayer':AttenLayer})\n",
        "        return model\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data is uploaded on Google Drive\n",
        "\n",
        "Inside the dataset, there are 7 different human activities: `bed`, `fall`, `pickup`, `run`, `sitdown`, `standup` and `walk`.\n",
        "\n",
        "Proccessing the data and merging into classes.\n"
      ],
      "metadata": {
        "id": "1ZmKTIpIGx6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_foler = '/content/drive/MyDrive/Dataset/Data'\n",
        "\n",
        "# preprocessing\n",
        "cfg = CSIModelConfig(win_len=1000, step=200, thrshd=0.6, downsample=2)\n",
        "numpy_tuple = cfg.preprocessing('/content/drive/MyDrive/Dataset/Data', save=True)\n",
        "# load previous saved numpy files, ignore this if you haven't saved numpy array to files before\n",
        "numpy_tuple = cfg.load_csi_data_from_files(('/content/drive/MyDrive/ProcessData/x_bed.npz', \n",
        "                                            '/content/drive/MyDrive/ProcessData/x_fall.npz', \n",
        "                                            '/content/drive/MyDrive/ProcessData/x_pickup.npz', \n",
        "                                            '/content/drive/MyDrive/ProcessData/x_run.npz', \n",
        "                                            '/content/drive/MyDrive/ProcessData/x_sitdown.npz', \n",
        "                                            '/content/drive/MyDrive/ProcessData/x_standup.npz', \n",
        "                                            '/content/drive/MyDrive/ProcessData/x_walk.npz'))"
      ],
      "metadata": {
        "id": "VCkekq8okhKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spliting Test Data and Test Data"
      ],
      "metadata": {
        "id": "ZI_K_3KxHBlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_bed, y_bed, x_fall, y_fall, x_pickup, y_pickup, x_run, y_run, x_sitdown, y_sitdown, x_standup, y_standup, x_walk, y_walk = numpy_tuple\n",
        "x_train, y_train, x_valid, y_valid = train_valid_split(\n",
        "    (x_bed, x_fall, x_pickup, x_run, x_sitdown, x_standup, x_walk),\n",
        "    train_portion=0.9, seed=379)"
      ],
      "metadata": {
        "id": "fMBc3rHHlCwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Model"
      ],
      "metadata": {
        "id": "czBmiatcHfLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters for Deep Learning Model\n",
        "model = cfg.build_model(n_unit_lstm=200, n_unit_atten=400)\n",
        "# train\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy', \n",
        "    metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=128, epochs=20,\n",
        "    validation_data=(x_valid, y_valid),\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.ModelCheckpoint('best_atten.hdf5',\n",
        "                                            monitor='val_accuracy',\n",
        "                                            save_best_only=True,\n",
        "                                            save_weights_only=False)\n",
        "            ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9--WOTilLZv",
        "outputId": "12938fef-dd9e-4283-9ccd-614105f6276f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 500, 90)]         0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 500, 400)         465600    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " atten_layer (AttenLayer)    (None, 400)               160800    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 7)                 2807      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 629,207\n",
            "Trainable params: 629,207\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "50/50 [==============================] - 25s 213ms/step - loss: 1.4290 - accuracy: 0.4845 - val_loss: 1.0897 - val_accuracy: 0.6573\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 8s 165ms/step - loss: 0.9858 - accuracy: 0.6904 - val_loss: 0.8665 - val_accuracy: 0.7374\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 9s 171ms/step - loss: 0.8252 - accuracy: 0.7473 - val_loss: 0.7207 - val_accuracy: 0.7879\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 9s 172ms/step - loss: 0.7116 - accuracy: 0.7843 - val_loss: 0.6300 - val_accuracy: 0.7992\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 53s 1s/step - loss: 0.6104 - accuracy: 0.8148 - val_loss: 0.5359 - val_accuracy: 0.8427\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.5609 - accuracy: 0.8361 - val_loss: 0.4807 - val_accuracy: 0.8694\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 9s 171ms/step - loss: 0.5040 - accuracy: 0.8562 - val_loss: 0.4490 - val_accuracy: 0.8834\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 8s 170ms/step - loss: 0.4642 - accuracy: 0.8658 - val_loss: 0.3983 - val_accuracy: 0.9003\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 9s 171ms/step - loss: 0.4220 - accuracy: 0.8810 - val_loss: 0.3870 - val_accuracy: 0.9031\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 0.3920 - accuracy: 0.8945 - val_loss: 0.3398 - val_accuracy: 0.9256\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 8s 165ms/step - loss: 0.3585 - accuracy: 0.9053 - val_loss: 0.3445 - val_accuracy: 0.9228\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 8s 163ms/step - loss: 0.3342 - accuracy: 0.9116 - val_loss: 0.2904 - val_accuracy: 0.9284\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 8s 164ms/step - loss: 0.3164 - accuracy: 0.9176 - val_loss: 0.2976 - val_accuracy: 0.9438\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 8s 165ms/step - loss: 0.3187 - accuracy: 0.9152 - val_loss: 0.2808 - val_accuracy: 0.9382\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 8s 169ms/step - loss: 0.2718 - accuracy: 0.9316 - val_loss: 0.2399 - val_accuracy: 0.9340\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2553 - accuracy: 0.9341 - val_loss: 0.2420 - val_accuracy: 0.9494\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 9s 174ms/step - loss: 0.2343 - accuracy: 0.9421 - val_loss: 0.2321 - val_accuracy: 0.9494\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 0.2270 - accuracy: 0.9425 - val_loss: 0.2133 - val_accuracy: 0.9522\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 0.2087 - accuracy: 0.9499 - val_loss: 0.2000 - val_accuracy: 0.9551\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 8s 168ms/step - loss: 0.1973 - accuracy: 0.9526 - val_loss: 0.1916 - val_accuracy: 0.9635\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f30a076eeb0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating Model"
      ],
      "metadata": {
        "id": "o_a88R3KK504"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # load the best model\n",
        "model = cfg.load_model('best_atten.hdf5')\n",
        "y_pred = model.predict(x_valid)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lhI0dCrZlRQc",
        "outputId": "01354a85-b719-41e8-aff1-33af37b8198f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 2s 31ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy Metric"
      ],
      "metadata": {
        "id": "rHkzpFXJK_sb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        " \n",
        "accuracy = tf.metrics.Accuracy()\n",
        "\n",
        "accuracy.update_state(np.argmax(y_valid, axis=1), np.argmax(y_pred, axis=1))\n",
        "result = accuracy.result()\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3m6nqR6nI25O",
        "outputId": "0f7fb587-f4aa-4678-f454-cdf5aee14194"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.96348315, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Metrics\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qEtl_eGrLC2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "confusion_matrix = metrics.confusion_matrix(np.argmax(y_valid, axis=1), np.argmax(y_pred, axis=1))\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [\"bed\", \"fall\", \n",
        "                                                                                                   \"pickup\", \"run\", \n",
        "                                                                                                   \"sitdown\", \"standup\", \"walk\"])\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yOPkKe5e84f-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "3c3f5507-4029-4947-e403-1db4e1ae011e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}